{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Optimizing models\n",
    "\n",
    "Evaluation is not only meant to be a reality-check of how well a model measures up to our expectations.\n",
    "This notebook demonstrates how to evaluate models better, and more importantly, how to optimize a model's performance with just a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll use the Titanic dataset to train decision trees.\n",
    "All of the examples will show how different evaluation measures and optimization techniques lead to very different trees.\n",
    "The next code cell loads the dataset into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # import pandas\n",
    "df = pd.read_csv('data/titanic-train.csv') # read the Titanic dataset into a DataFrame\n",
    "df.head() # show the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this notebook, we'll only be using a few features from this dataset.\n",
    "Normally, you would experiment with most features, but we'll ignore rows with many missing values and categorical variables to get to optimization techniques more quickly.\n",
    "The next code cell shows some statistics from the Titanic dataset, including the number of rows, the number of missing values and the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "_df = df.copy() # create a copy of the dataset before imputation\n",
    "_df.info() # print information about the columns, including missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting to train the decision tree, the next code cell encodes the `Sex` feature, which we know to be important to predict survival, and impute the missing `Age` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] are ['female', 'male']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        S  \n",
       "1          PC 17599  71.2833   C85        C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3            113803  53.1000  C123        S  \n",
       "4            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing # import the preprocessing module for feature engineering\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder() # create the label encoder\n",
    "encoding = label_encoder.fit_transform(_df.Sex) # encode the `Sex` feature\n",
    "_df.Sex = encoding # replace the encoded `Sex` values\n",
    "print(f\"{ [ 0, 1 ] } are { list(label_encoder.inverse_transform([ 0, 1 ])) }\")\n",
    "\n",
    "_df.Age = _df.Age.fillna(_df.Age.mean()) # fill the Age's missing values with the mean\n",
    "_df.head() # show the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "K-fold cross validation gives us more reliable results by, well, cross validating using several train and test sets.\n",
    "Instead of training a single model, k-fold cross validation trains several models, always using different training and test sets.\n",
    "\n",
    "In scikit-learn, there are two ways of applying k-fold cross validation, but in either way, the first step is to identify the features and labels.\n",
    "The next code cell specifies the features we'll use to train decision trees with, and then it extracts all features `X` and labels `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare' ] # the subset of the features we're using\n",
    "X = _df[ features ] # keep all rows, but only some of the features\n",
    "y = _df.Survived # keep all the labels in the `Survived` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first k-fold cross validation experiment we'll perform gives us complete control and visibility of the evaluation process.\n",
    "We'll use the [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) class to perform cross validation, which involves two steps:\n",
    "\n",
    "1. Import the `KFold` class\n",
    "2. Instantiate the `KFold` class\n",
    "\n",
    "The next code cell performs both steps, instantiating the class with 5 splits ($k=5$).\n",
    "We also shuffle all rows, an optional parameter that gives us different results whenever we run the experiment.\n",
    "\n",
    "The `splits` variable is a list, which holds a number of splits, as the name implies.\n",
    "Each split is made up of two lists, each containing indices:\n",
    "\n",
    "1. The first list is the examples that we should use to **train** the model.\n",
    "2. The second list is the examples that we should use to **test** the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  25,  27,  28,\n",
       "         29,  30,  31,  32,  33,  35,  38,  39,  42,  45,  47,  49,  50,\n",
       "         51,  52,  53,  54,  55,  56,  57,  58,  59,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  71,  72,  73,  74,  75,  76,  77,  79,\n",
       "         80,  81,  82,  83,  84,  86,  88,  89,  90,  93,  96,  97,  98,\n",
       "         99, 101, 102, 103, 104, 105, 109, 110, 111, 112, 115, 116, 118,\n",
       "        121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 133, 134, 135,\n",
       "        139, 140, 141, 142, 143, 145, 147, 148, 149, 151, 152, 153, 154,\n",
       "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "        168, 169, 170, 171, 173, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "        196, 197, 199, 200, 202, 203, 204, 208, 209, 210, 211, 212, 213,\n",
       "        214, 216, 217, 218, 219, 220, 222, 223, 224, 225, 226, 227, 228,\n",
       "        229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 243, 244,\n",
       "        245, 246, 247, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "        260, 261, 262, 264, 266, 267, 268, 271, 273, 274, 275, 278, 279,\n",
       "        280, 281, 282, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297,\n",
       "        299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
       "        313, 314, 315, 316, 317, 318, 319, 320, 321, 324, 326, 327, 328,\n",
       "        331, 332, 334, 336, 338, 339, 340, 341, 342, 344, 345, 347, 348,\n",
       "        350, 351, 352, 353, 354, 355, 356, 357, 360, 361, 362, 363, 364,\n",
       "        365, 366, 367, 368, 370, 371, 372, 373, 374, 375, 377, 378, 380,\n",
       "        381, 382, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 396,\n",
       "        397, 400, 401, 402, 403, 405, 406, 407, 408, 409, 410, 412, 413,\n",
       "        414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 428, 429,\n",
       "        430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 441, 444, 446,\n",
       "        447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
       "        460, 461, 462, 463, 465, 466, 468, 469, 471, 472, 473, 474, 476,\n",
       "        479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "        493, 494, 495, 497, 498, 499, 500, 501, 502, 503, 505, 507, 510,\n",
       "        511, 512, 513, 514, 515, 516, 518, 519, 520, 521, 522, 523, 524,\n",
       "        525, 527, 528, 529, 530, 531, 533, 534, 535, 536, 537, 538, 539,\n",
       "        541, 542, 543, 545, 546, 547, 548, 550, 551, 552, 553, 554, 555,\n",
       "        557, 558, 559, 560, 561, 562, 563, 564, 567, 570, 572, 573, 574,\n",
       "        575, 576, 577, 578, 579, 580, 582, 583, 584, 585, 588, 590, 591,\n",
       "        592, 593, 594, 595, 596, 598, 599, 600, 601, 604, 605, 607, 608,\n",
       "        609, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622,\n",
       "        624, 625, 626, 628, 630, 631, 632, 633, 634, 636, 637, 638, 639,\n",
       "        642, 644, 645, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656,\n",
       "        657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 669, 670,\n",
       "        671, 673, 674, 676, 678, 679, 680, 681, 682, 683, 684, 685, 686,\n",
       "        687, 688, 689, 690, 691, 692, 693, 694, 695, 697, 698, 700, 702,\n",
       "        703, 704, 705, 706, 707, 708, 710, 711, 713, 714, 715, 716, 718,\n",
       "        719, 722, 723, 724, 726, 727, 728, 729, 730, 732, 733, 734, 735,\n",
       "        736, 737, 738, 741, 744, 745, 746, 747, 748, 749, 750, 751, 752,\n",
       "        753, 756, 757, 758, 759, 761, 762, 764, 766, 767, 768, 769, 770,\n",
       "        771, 772, 773, 774, 776, 777, 778, 779, 780, 781, 782, 783, 784,\n",
       "        785, 786, 787, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799,\n",
       "        800, 801, 802, 803, 804, 805, 806, 807, 808, 810, 812, 813, 814,\n",
       "        815, 817, 818, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829,\n",
       "        830, 833, 834, 835, 836, 837, 838, 839, 841, 842, 844, 845, 847,\n",
       "        848, 849, 850, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861,\n",
       "        862, 863, 865, 868, 869, 870, 871, 872, 873, 875, 876, 877, 879,\n",
       "        880, 881, 882, 883, 884, 885, 886, 888, 889, 890]),\n",
       " array([ 10,  24,  26,  34,  36,  37,  40,  41,  43,  44,  46,  48,  60,\n",
       "         70,  78,  85,  87,  91,  92,  94,  95, 100, 106, 107, 108, 113,\n",
       "        114, 117, 119, 120, 130, 132, 136, 137, 138, 144, 146, 150, 172,\n",
       "        174, 198, 201, 205, 206, 207, 215, 221, 239, 241, 242, 248, 249,\n",
       "        263, 265, 269, 270, 272, 276, 277, 283, 284, 285, 286, 289, 298,\n",
       "        300, 322, 323, 325, 329, 330, 333, 335, 337, 343, 346, 349, 358,\n",
       "        359, 369, 376, 379, 383, 389, 395, 398, 399, 404, 411, 425, 426,\n",
       "        427, 440, 442, 443, 445, 464, 467, 470, 475, 477, 478, 492, 496,\n",
       "        504, 506, 508, 509, 517, 526, 532, 540, 544, 549, 556, 565, 566,\n",
       "        568, 569, 571, 581, 586, 587, 589, 597, 602, 603, 606, 610, 623,\n",
       "        627, 629, 635, 640, 641, 643, 646, 668, 672, 675, 677, 696, 699,\n",
       "        701, 709, 712, 717, 720, 721, 725, 731, 739, 740, 742, 743, 754,\n",
       "        755, 760, 763, 765, 775, 788, 789, 809, 811, 816, 819, 831, 832,\n",
       "        840, 843, 846, 851, 864, 866, 867, 874, 878, 887]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold # import the KFold class\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True) # create the k-fold cross validation class with k=5 and shuffling\n",
    "splits = list(folds.split(X)) # extract the folds as a list\n",
    "splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way scikit-learn applies k-fold cross validation, we need to give it a model with all hyperparameters set.\n",
    "In other words, we create the model, but without training it.\n",
    "We'll train the decision tree later for each different split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree # import the tree module\n",
    "dt = tree.DecisionTreeClassifier(max_leaf_nodes=5) # create the DecisionTreeClassifier—but do not train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have the two tools that we need to cross-validate: a list of splits and a decision tree.\n",
    "The next code cell performs a few, very simple steps:\n",
    "\n",
    "1. It iterates over every split: a training set and a test set.\n",
    "2. It trains the model on the training set.\n",
    "3. It evaluates the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure: 75.71%\n",
      "F-measure: 60.78%\n",
      "F-measure: 70.68%\n",
      "F-measure: 69.7%\n",
      "F-measure: 72.06%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics # import the metrics module\n",
    "for train_index, test_index in splits: # go through each split: a training set and a test set\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index] # extract the train and test rows (but only the features)\n",
    "    y_train, y_test = y[train_index], y[test_index] # extract the train and test labels\n",
    "    \n",
    "    dt = dt.fit(X_train, y_train) # train, or fit, the decision tree\n",
    "    \n",
    "    y_pred = dt.predict(X_test) # predict the labels of the unseen observations\n",
    "    print(f\"F-measure: { round(metrics.f1_score(y_test, y_pred) * 100, 2) }%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that no matter how many times you run this notebook, the average results are always similar.\n",
    "That is what makes k-fold cross validation more reliable than evaluating with one split.\n",
    "\n",
    "There are more ways to improve the reliability *and* performance of models.\n",
    "For example, the [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) class is a stratified version of k-fold cross validation.\n",
    "Stratified sampling ensures that we do not have a train set with very few survivors or many surviors: the training and test sets are more consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second way of applying k-fold cross validation is also much more straightforward.\n",
    "In fact, it's straightforward enough to fit in one code cell.\n",
    "\n",
    "The solution is to use the [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function, which is really a shortcut to the `StratifiedKFold` class.\n",
    "To use this function, we naturally need to import it, but we also need to pass on a few parameters:\n",
    "\n",
    "- The model we want to use—instantiated, as before, but not trained\n",
    "- The features that the function will use to train the model, `X`, and the corresponding labels, `y`\n",
    "- The number of splits, `cv`\n",
    "- The scoring function—see the [scoring options here](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "\n",
    "The function will simply return the scores from each split.\n",
    "And we're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69089482, 0.77091377, 0.79400953, 0.72775306, 0.79657143])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score # import the cross_val_score function\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(max_leaf_nodes=5) # create the DecisionTreeClassifier\n",
    "cross_val_score(dt, X, y, cv=5, scoring='f1_macro') # calculate the F1-score with 5 splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Tuning hyperparameters can be tedious, but scikit-learn can do it for you.\n",
    "We'll first experiment with [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "As usual, we have to import the class, but more importantly, we need to pass on at least two parameters: the model and all possible hyperparameters we want to try.\n",
    "For example, we'll vary the maximum depth and leaf nodes from 2 to 19.\n",
    "\n",
    "We also set `cv=5` for 5-fold, stratified cross validation, and choose the scoring metric.\n",
    "After fitting, we can view the best hyperparameters (`best_params_`) and score (`best_score_`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best results: {'max_depth': 10, 'max_leaf_nodes': 19}\n",
      "F-measure: 80.93%\n",
      "CPU times: user 6.81 s, sys: 0 ns, total: 6.81 s\n",
      "Wall time: 6.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ^ time how long it takes grid search to find the best hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV # import the GridSearchCV class\n",
    "\n",
    "dt = tree.DecisionTreeClassifier() # create a decision tree with any default hyperparameters\n",
    "parameters = { 'max_depth': range(2, 20), 'max_leaf_nodes': range(2, 20) } # choose the hyparameters that you want to experiment with\n",
    "\n",
    "# instantiate the grid search with the model and all possible parameters, as well as some other optional parameters\n",
    "grid = GridSearchCV(dt, parameters, cv=5, scoring='f1_macro')\n",
    "\n",
    "grid.fit(X, y) # tune the parameters\n",
    "print(f\"Best results: { grid.best_params_ }\")\n",
    "print(f\"F-measure: { round(grid.best_score_ * 100, 2) }%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how long it takes: that's grid search.\n",
    "[RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) takes much less time, but the score trade-off isn't large.\n",
    "Best of all, the code is practically the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best results: {'max_leaf_nodes': 14, 'max_depth': 9}\n",
      "F-measure: 80.56%\n",
      "CPU times: user 114 ms, sys: 0 ns, total: 114 ms\n",
      "Wall time: 113 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# ^ time how long it takes random search to find the best hyperparameters\n",
    "from sklearn.model_selection import RandomizedSearchCV # import the RandomizedSearchCV class\n",
    "\n",
    "dt = tree.DecisionTreeClassifier() # create a decision tree with any default hyperparameters\n",
    "parameters = { 'max_depth': range(2, 20), 'max_leaf_nodes': range(2, 20) } # choose the hyparameters that you want to experiment with\n",
    "\n",
    "# instantiate the random search with the model and all possible parameters, as well as some other optional parameters\n",
    "rand = RandomizedSearchCV(dt, parameters, n_iter=5, cv=5, scoring='f1_macro')\n",
    "\n",
    "rand.fit(X, y) # tune the parameters\n",
    "print(f\"Best results: { rand.best_params_ }\")\n",
    "print(f\"F-measure: { round(rand.best_score_ * 100, 2) }%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning does not have to a chore, and sometimes making some extra effort can improve results considerably."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
