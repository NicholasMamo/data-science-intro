{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Imbalanced data\n",
    "\n",
    "Imbalanced data is a problem that is present in almost any dataset.\n",
    "In some datasets, the problem is barely noticeable; in others, the imbalance is the only thing you can see.\n",
    "In either case, re-balancing the data can improve results.\n",
    "\n",
    "In this notebook, we explore different techniques to undersample or oversample imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To re-balance datasets, we won't use `scikit-learn`, but `imbalanced-learn`, another Python package based on `scikit-learn`.\n",
    "You can either install `imbalanced-learn` through Conda or uncomment the following line of code by removing the `#` symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\nicho\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nicho\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by importing some of the datasets we'll use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn # the imbalanced-learn package\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling\n",
    "\n",
    "Undersampling is only really feasible in very large datasets.\n",
    "To save some processing time, we focus on a relatively small dataset that has already been pre-processed for us: part of the Enron spam email dataset.\n",
    "\n",
    "The next cell loads the dataset and removes the `Email No.` column, which is a unique identifier.\n",
    "Finally, the code cell concludes by counting the number of emails that have a label of 0 (not spam) and 1 (spam).\n",
    "As you can see, the dataset has a large imbalance, with around 70% being non-spam emails.\n",
    "\n",
    "> Note: When dropping the `Email No.` column, we specify `axis=1`.\n",
    "        Axis 0 are the rows, and axis 1 are the columns.\n",
    "        By specifying `axis=1`, we're telling pandas to look for the `Email No.` as a column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction\n",
       "0    3672\n",
       "1    1500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/emails.csv') # read the dataset from file and into a pandas DataFrame\n",
    "df = df.drop(\"Email No.\", axis=1) # remove the `Email No.` column since it's a unique identifier\n",
    "df.groupby(by='Prediction').size() # group the emails by their prediction and count the number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`imbalanced-learn` is based on `scikit-learn`, and it shows.\n",
    "Like `scikit-learn`, you'll normally follow three steps to undersample or oversample a dataset:\n",
    "\n",
    "1. Import the module and class\n",
    "2. Instantiate the class with any parameters\n",
    "3. Fit and resample (instead of fit and predict or fit and transform) the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For undersampling, we'll use a random undersampler, aptly-called [`RandomUnderSampler`](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.RandomUnderSampler.html).\n",
    "This undersampler is very simple and randomly removes extra instances from the majority class.\n",
    "\n",
    "When undersampling or oversampling with `imbalanced-learn`, we have to provide the features and the label separately.\n",
    "The label allows the class to identify the majority class (when undersampling) or the minority class (when oversampling) and tweaking the dataset accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: import the random undersampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# step 2: create the undersampler\n",
    "undersample = RandomUnderSampler()\n",
    "\n",
    "# step 3: fit and resample the data\n",
    "features = df.columns[ ~df.columns.isin([ 'Prediction' ]) ] # the words, or the features in their emails, but excluding the label\n",
    "X, y = df.loc[:, features], df.Prediction # extract the features (X) and the labels (y)\n",
    "X_under, y_under = undersample.fit_resample(X, y) # finally, resample!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit_resample` function returned two variables: the `X_under` and the `y_under`.\n",
    "The `X_under` is the new data in our dataset, with more than half of the original rows of the majority removed.\n",
    "The `y_under` are the remaining labels.\n",
    "\n",
    "The next code cell loads this re-balanced data into a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction\n",
       "0    1500\n",
       "1    1500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new DataFrame with the column names taken from above and the re-balanced data\n",
    "_df = pd.DataFrame(columns=features, data=X_under)\n",
    "_df[ 'Prediction' ] = y_under # copy back the labels\n",
    "_df.groupby(by='Prediction').size() # group the emails by their prediction and count the number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, now the dataset is balanced again, with 1500 emails marked as not spam, and 1500 marked as spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling\n",
    "\n",
    "The process for oversampling is almost identical.\n",
    "This time, we use the Titanics dataset, where undersampling is not an option because the dataset is so small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/titanic-train.csv') # read the Titanic dataset into a DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is again very imbalanced: only 40% of Titanic passengers survived.\n",
    "Since the dataset is so small, undersampling would not make sense, as we would have to remove more than 200 passengers who did not survive, or more than 20% of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    342\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by='Survived').size() # group the passengers by their survival flag and count the rows in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling with `imbalanced-learn` is almost identical to undersampling.\n",
    "There are three steps again, this time importing and instantiating the [`RandomOverSampler`](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html) instead of the `UnderSampler` class.\n",
    "\n",
    "Again, not that we pass on the features and label separately so that the RandomOverSampler knows which class to over-sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: import the random oversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# step 2: create the oversampler\n",
    "oversample = RandomOverSampler()\n",
    "\n",
    "# step 3: fit and resample the data\n",
    "X, y = df.loc[:,  ~df.columns.isin([ 'Survived' ]) ], df.Survived # oversample all features except the label\n",
    "X_over, y_over = oversample.fit_resample(X, y) # oversample the features and the label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the DataFrame anew, note how the minority class (when the `Survived` label is 1) now has many rows as the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    549\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new DataFrame with the column names taken from the original DataFrame and the re-balanced data\n",
    "_df = pd.DataFrame(columns=df.columns, data=X_over)\n",
    "_df[ 'Survived' ] = y_over # copy back the labels\n",
    "_df.groupby(by='Survived').size() # group the passengers by their survival flag and count the rows in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "\n",
    "Oversampling with SMOTE is a little bit different.\n",
    "First, we have to decide what version of SMOTE is most appropriate for our data.\n",
    "`imbalanced-learn` provides different implementations, including:\n",
    "\n",
    "- [`SMOTE`](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html): the basic implementation of SMOTE, which assumes that all the features are continuous\n",
    "- [`SMOTEN`](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTEN.html): an implementation of SMOTE that's used when the data is entirely categorical\n",
    "- [`SMOTENC`](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html): an implemetation of SMOTE that's used when some of the data, but not all of it, is categorical\n",
    "\n",
    "The Titanic dataset is a mix of continuous and categorical data, so we can only use SMOTENC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE and its variations complain about missing values.\n",
    "The next code cell loads a summary of the features with missing data, namely `Age` and `Embarked`.\n",
    "We'll ignore the `PassengerId`, `Ticket` and `Embarked` features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "_df = df.copy() # create a copy of the dataframe so we don't overwrite the original data\n",
    "_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll take a very simple approach to imputation.\n",
    "Since there are only 2 missing `Embarked` values, we drop all rows that do not have a value.\n",
    "We'll fill in the missing `Age` values with the average.\n",
    "Check out the imputation notebook for more sophisticated techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = _df.dropna(subset=[ 'Embarked' ]) # drop all rows with missing values for the `Embarked` future\n",
    "_df.Age = _df.Age.fillna(_df.Age.mean()) # fill in missing `Age` values with the average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell filters out unnecessary columns, and we focus instead on 7 features.\n",
    "Note that there is no need for feature engineering at this stage: `imbalanced-learn` automatically notices that the `Pclass` feature (the passenger class) is an integer, so it should not take a floating-point value.\n",
    "Similarly, the `Sex` and `Embarked` columns will only take valid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'Age', 'Fare', 'Pclass', 'SibSp', 'Parch', 'Sex', 'Embarked' ] # the list of features we want to focus on\n",
    "_df = _df[ features + [ 'Survived' ] ] # filter the DataFrame's column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, finally, we can over-sample using SMOTE.\n",
    "Since we're using SMOTENC, we need to tell the class which features are categorical upon instantiation.\n",
    "This parameter is a list of booleans (`True` or `False`) indicating which columns are categorical.\n",
    "Aside from this extra step, everything the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: import SMOTENC\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "# step 2: create the SMOTENC class\n",
    "categorical = [ feature in [ 'Embarked', 'Sex' ] for feature in features ] # choose the categorical features\n",
    "smote_nc = SMOTENC(categorical_features=categorical)\n",
    "\n",
    "X, y = _df[ features ], _df.Survived  # oversample all features except the label\n",
    "X_over, y_over = smote_nc.fit_resample(X, y) # oversample the features and the label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we insert the data into a new DataFrame, we can observe how now, the number of passengers who survived and those who did not survive are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    549\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new DataFrame with the column names taken from the original DataFrame and the re-balanced data\n",
    "__df = pd.DataFrame(columns=_df.columns, data=X_over)\n",
    "__df[ 'Survived' ] = y_over # copy back the labels\n",
    "__df.groupby(by='Survived').size() # group the passengers by their survival flag and count the rows in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell shows the last 10 rows created by SMOTENC.\n",
    "Do you notice something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>49.864726</td>\n",
       "      <td>26.550000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>27.069175</td>\n",
       "      <td>53.071200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>34.862949</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>54.305373</td>\n",
       "      <td>78.314201</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>33.198225</td>\n",
       "      <td>53.072952</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>29.642093</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>41.916801</td>\n",
       "      <td>52.554200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>23.156523</td>\n",
       "      <td>14.246915</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>22.321640</td>\n",
       "      <td>55.047356</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age        Fare  Pclass  SibSp  Parch     Sex Embarked  Survived\n",
       "1088  49.864726   26.550000       1      0      0  female        S         1\n",
       "1089  27.069175   53.071200       1      1      0  female        S         1\n",
       "1090  29.642093   34.862949       1      0      0    male        S         1\n",
       "1091  54.305373   78.314201       1      1      0  female        C         1\n",
       "1092  36.000000  120.000000       1      1      2  female        C         1\n",
       "1093  33.198225   53.072952       1      1      0  female        S         1\n",
       "1094  29.642093    7.750000       3      0      0  female        Q         1\n",
       "1095  41.916801   52.554200       1      1      0  female        S         1\n",
       "1096  23.156523   14.246915       2      0      0  female        S         1\n",
       "1097  22.321640   55.047356       1      0      0    male        S         1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "If you want to learn more about the `imbalanced-learn` library, you can visit the documentation site [here](https://imbalanced-learn.org/stable/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
